{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fire or Not?  \n",
    "<hr style=\"border:2px solid magenta\"> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Description** \n",
    "* Wildfires are very unpredictable and can occur randomly. Using sattelite images, we can in real time detect a wildfire and warn the proper authorities to mitigate the outgoing damage from wildfires. \n",
    "\n",
    "**Objective**\n",
    "* Create a model that can detect if there is a wildfire in the image with a high f1 score as this is a measure that combines recall and precision of the model. We would want authorities to respond to a real wildfire and false alarm rather than not be alerted that there is a wildfire. It is better to be safe than sorry.  \n",
    "\n",
    "**Methodology**\n",
    "* Using a Convolutional Neural Network for wildfire detection. The architecture was designed usign Keras API and was implemented using Python, Tensorflow.  \n",
    "\n",
    "**Data**\n",
    "* The dataset was provided by Kaggle: [Wildfire Prediction Dataset (Satellite Images)](https://www.kaggle.com/datasets/abdelghaniaaba/wildfire-prediction-dataset/data). It has been divided into three directories: test, train, and validation. The file name are the coordinates of the wildfire location."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports\n",
    "<hr style=\"border:2px solid magenta\">  \n",
    "\n",
    "Grabbing the important imports needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from pathlib import Path\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPooling2D, BatchNormalization\n",
    "from tensorflow.keras import backend\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from tensorflow.keras.metrics import Recall, Precision, AUC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.extract_to_df import extract_to_df\n",
    "from src.visualizations import plot_cm, plot_graph\n",
    "from src.metric_notes import metric_note"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#prevent a bug that some images are truncated\n",
    "from PIL import ImageFile\n",
    "ImageFile.LOAD_TRUNCATED_IMAGES = True\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extracting Data  \n",
    "<hr style=\"border:2px solid magenta\">  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setting the paths to the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = Path('Data/test')\n",
    "train = Path('Data/train')\n",
    "valid = Path('Data/valid')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using a function called extract_to_df that is in the src folder. This function will extract useful information from each file and return a dataframe containing the relative path, latitude and longtitude coordinates, and the class of the image : wildfire or nowildfire. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = extract_to_df(train, 'Train')\n",
    "test_df = extract_to_df(test, 'Test')\n",
    "val_df = extract_to_df(valid,'Valid')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating the generators used to extract the images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_generator = tf.keras.preprocessing.image.ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    width_shift_range = 0.2, \n",
    "    height_shift_range = 0.2,\n",
    "    horizontal_flip = True, \n",
    "    vertical_flip = True\n",
    ")\n",
    "\n",
    "test_generator = tf.keras.preprocessing.image.ImageDataGenerator(\n",
    "    rescale = 1./255\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extracting images. Starting with 32x32 pixels. Might change it to 64x64 or 224x224 which is another image size standard. Pixel can be changed for the images. It helps with renaming the files and such later on. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "pixel = 32\n",
    "size = f'{pixel}x{pixel}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 30250 validated image filenames belonging to 2 classes.\n",
      "Found 6300 validated image filenames belonging to 2 classes.\n",
      "Found 6300 validated image filenames belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "train_images = train_generator.flow_from_dataframe(dataframe=train_df,\n",
    "                                                 x_col = 'Path',\n",
    "                                                 y_col = 'Label',                           \n",
    "                                                 target_size = (pixel,pixel),\n",
    "                                                 class_mode = 'binary',\n",
    "                                                 color_mode = 'rgb',\n",
    "                                                 shuffle = True,\n",
    "                                                 seed = 42,\n",
    "                                                 batch_size = 128)\n",
    "\n",
    "valid_images = train_generator.flow_from_dataframe(dataframe=val_df,\n",
    "                                                 x_col = 'Path',\n",
    "                                                 y_col = 'Label',                           \n",
    "                                                 target_size=(pixel,pixel),\n",
    "                                                 class_mode = 'binary',\n",
    "                                                 color_mode = 'rgb',\n",
    "                                                 shuffle = True,\n",
    "                                                 seed = 42,\n",
    "                                                 batch_size = 64)\n",
    "\n",
    "test_images = test_generator.flow_from_dataframe(dataframe=test_df,\n",
    "                                                 x_col='Path',\n",
    "                                                 y_col='Label',\n",
    "                                                 target_size=(pixel,pixel),\n",
    "                                                 class_mode='binary',\n",
    "                                                 color_mode='rgb',\n",
    "                                                 shuffle=True,\n",
    "                                                 seed=42,\n",
    "                                                 batch_size=128)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is a lot of images already. Roughly 42850 images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = metric_note(train_images, test_images, valid_images)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modeling TIME  \n",
    "<hr style=\"border:2px solid magenta\">  \n",
    "\n",
    "Let's do a simple CNN with 1-Convolutional Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn1 = Sequential()\n",
    "cnn1.add(Conv2D(filters=32,\n",
    "                kernel_size=(3, 3),\n",
    "                activation='relu',\n",
    "                input_shape=(pixel,pixel, 3)))\n",
    "cnn1.add(MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "cnn1.add(Flatten())\n",
    "\n",
    "cnn1.add(Dense(128, activation='relu'))\n",
    "cnn1.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "cnn1.compile(optimizer='adam',\n",
    "             loss='binary_crossentropy',\n",
    "             metrics=['accuracy', Precision(), Recall(), AUC()])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adding an early stopping to prevent overfitting and save computational resources and time. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stop = tf.keras.callbacks.EarlyStopping(\n",
    "            monitor='loss',\n",
    "            patience=4,\n",
    "            restore_best_weights=True\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fit the train_images into this one deep cnn with a batch size of 64, epochs of 50, validation data with valid_iamges. Using the early stopping for the reason mentioned above and using workers of 6 (Which I believe is similar to n_jobs in sklearn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "237/237 [==============================] - 27s 99ms/step - loss: 0.3089 - accuracy: 0.8688 - precision: 0.8711 - recall: 0.8780 - auc: 0.9409 - val_loss: 0.2286 - val_accuracy: 0.9125 - val_precision: 0.9254 - val_recall: 0.9155 - val_auc: 0.9693\n",
      "Epoch 2/5\n",
      "237/237 [==============================] - 70s 290ms/step - loss: 0.2417 - accuracy: 0.9048 - precision: 0.8910 - recall: 0.9310 - auc: 0.9633 - val_loss: 0.2332 - val_accuracy: 0.9054 - val_precision: 0.8690 - val_recall: 0.9759 - val_auc: 0.9734\n",
      "Epoch 3/5\n",
      "237/237 [==============================] - 55s 228ms/step - loss: 0.2316 - accuracy: 0.9072 - precision: 0.8921 - recall: 0.9349 - auc: 0.9664 - val_loss: 0.2213 - val_accuracy: 0.9119 - val_precision: 0.9318 - val_recall: 0.9069 - val_auc: 0.9744\n",
      "Epoch 4/5\n",
      "237/237 [==============================] - 20s 82ms/step - loss: 0.2188 - accuracy: 0.9121 - precision: 0.8971 - recall: 0.9387 - auc: 0.9699 - val_loss: 0.2233 - val_accuracy: 0.9132 - val_precision: 0.9470 - val_recall: 0.8928 - val_auc: 0.9773\n",
      "Epoch 5/5\n",
      "237/237 [==============================] - 19s 81ms/step - loss: 0.2124 - accuracy: 0.9186 - precision: 0.9072 - recall: 0.9398 - auc: 0.9708 - val_loss: 0.1939 - val_accuracy: 0.9238 - val_precision: 0.9386 - val_recall: 0.9224 - val_auc: 0.9784\n"
     ]
    }
   ],
   "source": [
    "results1 = cnn1.fit(train_images,\n",
    "                    batch_size = 64, \n",
    "                    epochs = 50,\n",
    "                    validation_data = valid_images,\n",
    "                    callbacks = [early_stop],\n",
    "                    workers = 6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Already at 95% accurate and 0.1220 log loss. This is a strong model already."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "237/237 [==============================] - 49s 207ms/step - loss: 0.2049 - accuracy: 0.9202 - precision: 0.9195 - recall: 0.9279 - auc: 0.9735\n",
      "50/50 [==============================] - 54s 1s/step - loss: 0.2679 - accuracy: 0.9044 - precision: 0.9715 - recall: 0.8520 - auc: 0.9787\n",
      "99/99 [==============================] - 10s 105ms/step - loss: 0.1903 - accuracy: 0.9260 - precision: 0.9404 - recall: 0.9247 - auc: 0.9792\n"
     ]
    }
   ],
   "source": [
    "metrics.evaluate(cnn1, 'CNN 1', size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Size</th>\n",
       "      <th>train log_loss</th>\n",
       "      <th>train accuracy</th>\n",
       "      <th>train precision</th>\n",
       "      <th>train recall</th>\n",
       "      <th>train auc</th>\n",
       "      <th>test log_loss</th>\n",
       "      <th>test accuracy</th>\n",
       "      <th>test precision</th>\n",
       "      <th>test recall</th>\n",
       "      <th>test auc</th>\n",
       "      <th>val log_loss</th>\n",
       "      <th>val accuracy</th>\n",
       "      <th>val precision</th>\n",
       "      <th>val recall</th>\n",
       "      <th>val auc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CNN1</td>\n",
       "      <td>32x32</td>\n",
       "      <td>0.204928</td>\n",
       "      <td>0.920165</td>\n",
       "      <td>0.919472</td>\n",
       "      <td>0.927936</td>\n",
       "      <td>0.973508</td>\n",
       "      <td>0.267886</td>\n",
       "      <td>0.904444</td>\n",
       "      <td>0.971494</td>\n",
       "      <td>0.852012</td>\n",
       "      <td>0.978724</td>\n",
       "      <td>0.190346</td>\n",
       "      <td>0.926032</td>\n",
       "      <td>0.940386</td>\n",
       "      <td>0.924713</td>\n",
       "      <td>0.979167</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Model   Size  train log_loss  train accuracy  train precision  train recall  \\\n",
       "0  CNN1  32x32        0.204928        0.920165         0.919472      0.927936   \n",
       "\n",
       "   train auc  test log_loss  test accuracy  test precision  test recall  \\\n",
       "0   0.973508       0.267886       0.904444        0.971494     0.852012   \n",
       "\n",
       "   test auc  val log_loss  val accuracy  val precision  val recall   val auc  \n",
       "0  0.978724      0.190346      0.926032       0.940386    0.924713  0.979167  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.printout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_graph(results1, size, 'CNN 1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "cnn1_predictions = plot_cm(cnn1, 'CNN 1', test_images, size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_true = test_images.labels, y_pred = cnn1_predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "backend.clear_session()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"border:2px solid magenta\">  \n",
    "\n",
    "Let's increase the complexity by making 4 deep. I am going to add some dropout and batchnormalization to help prevent overfitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn4 = Sequential()\n",
    "\n",
    "cnn4.add(Conv2D(filters=32,\n",
    "                kernel_size=3,\n",
    "                activation='relu',\n",
    "                input_shape=(pixel,pixel, 3)))\n",
    "cnn4.add(MaxPooling2D(pool_size=2))\n",
    "cnn4.add(BatchNormalization())\n",
    "cnn4.add(Dropout(0.2))\n",
    "\n",
    "cnn4.add(Conv2D(filters=32,\n",
    "                kernel_size=3,\n",
    "                activation='relu'))\n",
    "cnn4.add(MaxPooling2D(pool_size=2))\n",
    "cnn4.add(BatchNormalization())\n",
    "cnn4.add(Dropout(0.2))\n",
    "\n",
    "cnn4.add(Conv2D(filters=64,\n",
    "                kernel_size=3,\n",
    "                activation='relu'))\n",
    "cnn4.add(MaxPooling2D(pool_size=2))\n",
    "cnn4.add(BatchNormalization())\n",
    "cnn4.add(Dropout(0.2))\n",
    "\n",
    "cnn4.add(Conv2D(filters=128,\n",
    "                kernel_size=3,\n",
    "                activation='relu'))\n",
    "cnn4.add(MaxPooling2D(pool_size=2))\n",
    "cnn4.add(BatchNormalization())\n",
    "cnn4.add(Dropout(0.2))\n",
    "\n",
    "cnn4.add(Flatten())\n",
    "\n",
    "cnn4.add(Dense(128, activation='relu'))\n",
    "cnn4.add(BatchNormalization())\n",
    "cnn4.add(Dropout(0.2))\n",
    "\n",
    "cnn4.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "cnn4.compile(optimizer='adam',\n",
    "             loss='binary_crossentropy',\n",
    "             metrics=['accuracy', Precision(), Recall(), AUC()])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn4.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results4 = cnn4.fit(train_images,\n",
    "                    batch_size = 64, \n",
    "                    epochs = 50,\n",
    "                    validation_data = valid_images,\n",
    "                    callbacks = [early_stop],\n",
    "                    workers = 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_graph(results4, size, 'CNN 4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics.evaluate(cnn4, 'CNN 4', size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn4_predictions = plot_cm(cnn4, 'CNN 4', test_images, size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_true = test_images.labels, y_pred = cnn4_predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "backend.clear_session()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"border:2px solid magenta\">  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorgpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
